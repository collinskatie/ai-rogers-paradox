{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import jit\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd \n",
    "\n",
    "import importlib \n",
    "\n",
    "import simulation \n",
    "import utils\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_params_dict = {\n",
    "    \"N\": 1000, # Population size\n",
    "    # \"u\": 0.01, # Environmental change rate\n",
    "    \"u\": 0.0001,\n",
    "    \"c_I\": 0.05, # Cost of individual learning\n",
    "    \"c_AI\": 0.0, # Cost of AI update\n",
    "    \"z\": 0.66, # Success rate of individual learning\n",
    "    \"s0\": 0.85, # Survival probability (non-adapted)\n",
    "    \"s1\": 0.93, # Survival probability (adapted)\n",
    "    \"phi\": 1., # AI bias parameter\n",
    "    \"epsilon_I\": 0.0,  # Social learning error rate for humans\n",
    "    \"epsilon_AI\": 0.0, # Social learning error rate for AI\n",
    "    \"mu\": 0.005, # Mutation rate\n",
    "    \"n_records\": 200000, # Number of steps to average over\n",
    "    \"social_learning_mode\": \"both\", # Who can agents socially learn from: \"\", \"human\", \"ai\", \"both\"\n",
    "    \"resignation\": False, \n",
    "    \"resignation_hint\": 1,\n",
    "    \"ai_individ_learn\": False,\n",
    "    \"critical\": False, # Is critical social learning enabled\n",
    "    \"ind_penalty_mult\": 1., # How much is individual learning probability multiplied by after learning from AI\n",
    "    \"learn_twice\": False, # Should agent have second opportunity to learn if first one fails (only one of critical and learn_twice should be on at a time)\n",
    "    \"sim_name\": \"base\" # Name of current simulation (will be used in figure filenames)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict_local_base = copy.copy(base_params_dict) \n",
    "params_dict_local_base['social_learning_mode'] = 'ai'\n",
    "params_dict_local_base['sim_name'] = 'sec_3_1_2_override'\n",
    "params_dict_local_base['n_records'] = 1000\n",
    "\n",
    "critical_vary = [False, True]\n",
    "world_change_rates = {'slow': 0.01, 'moderate': 0.1, 'fast': 0.5}\n",
    "importlib.reload(utils)\n",
    "\n",
    "score_data = {\n",
    "    'critical': [], \n",
    "    'u': [],\n",
    "    'ai_bias': [],\n",
    "    'score': [],\n",
    "    'timestep': []\n",
    "}\n",
    "\n",
    "all_scores = []\n",
    "for allow_critical in critical_vary: \n",
    "    scores = []\n",
    "    for world_change, world_change_rate in world_change_rates.items(): \n",
    "        params_dict = copy.copy(params_dict_local_base)\n",
    "        params_dict['u'] = world_change_rate\n",
    "        params_dict['critical'] = allow_critical\n",
    "    \n",
    "\n",
    "        social_learner_freqs, ai_bias_means, change_points, ai_adaptation, learner_adaptation, social_learner_adaptation = simulation.run_simulation(\n",
    "            N=params_dict[\"N\"], n_generations=params_dict[\"n_records\"], u=params_dict[\"u\"], c_I=params_dict[\"c_I\"], c_AI=params_dict[\"c_AI\"],\n",
    "            z=params_dict[\"z\"], s0=params_dict[\"s0\"], s1=params_dict[\"s1\"], phi=params_dict[\"phi\"], epsilon_I=params_dict[\"epsilon_I\"], mu=params_dict[\"mu\"], n_records=params_dict[\"n_records\"],\n",
    "            social_learning_mode=params_dict[\"social_learning_mode\"], critical=params_dict[\"critical\"], ind_penalty_mult=params_dict[\"ind_penalty_mult\"], learn_twice=params_dict[\"learn_twice\"]\n",
    "        )\n",
    "        scores.append(learner_adaptation)#np.mean(learner_adaptation))\n",
    "        \n",
    "        for t, score in enumerate(learner_adaptation): \n",
    "            score_data['critical'].append(allow_critical)\n",
    "            score_data['u'].append(world_change),\n",
    "            score_data['score'].append(score)\n",
    "            score_data['timestep'].append(t)\n",
    "            score_data['ai_bias'].append(ai_bias_means[t]/ai_bias_means[t]+1)\n",
    "        \n",
    "        \n",
    "    all_scores.append(scores)\n",
    "df = pd.DataFrame.from_dict(score_data)\n",
    "\n",
    "# utils.plot_results(params_dict, social_learner_freqs, ai_bias_means, change_points, ai_adaptation, learner_adaptation, social_learner_adaptation)\n",
    "# print(np.mean(learner_adaptation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "# Set style\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Create figure and axis\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "soft_grey = '#808080'    # Soft grey\n",
    "soft_maroon = '#800000'  # Soft maroon\n",
    "\n",
    "# Create barplot for each u value and critical state\n",
    "positions = np.array([1, 2, 4, 5, 7, 8])  # Positions for bars with gaps between u groups\n",
    "labels = []\n",
    "\n",
    "for i, u in enumerate(world_change_rates):\n",
    "    # Filter data for each u value\n",
    "    u_data = df[df['u'] == u]\n",
    "    \n",
    "    # Calculate means for False and True critical states\n",
    "    mean_false = u_data[u_data['critical'] == False]['score'].mean()\n",
    "    mean_true = u_data[u_data['critical'] == True]['score'].mean()\n",
    "    \n",
    "    # Calculate standard errors\n",
    "    se_false = u_data[u_data['critical'] == False]['score'].std() / np.sqrt(len(u_data[u_data['critical'] == False]))\n",
    "    se_true = u_data[u_data['critical'] == True]['score'].std() / np.sqrt(len(u_data[u_data['critical'] == True]))\n",
    "    \n",
    "    # Create bars\n",
    "    ax.bar(positions[i*2], mean_false, width=0.6, yerr=se_false, capsize=5, color=soft_grey, \n",
    "           error_kw={'capthick': 1, 'elinewidth': 1.5})\n",
    "    ax.bar(positions[i*2 + 1], mean_true, width=0.6, yerr=se_true, capsize=5, color=soft_maroon,\n",
    "           error_kw={'capthick': 1, 'elinewidth': 1.5})\n",
    "    \n",
    "    labels.extend([f'[{u.capitalize()} change] \\nBase', f'\\nCritical'])\n",
    "\n",
    "# Customize plot\n",
    "ax.set_xticks(positions)\n",
    "ax.set_xticklabels(labels, rotation=45, ha='right')\n",
    "ax.set_ylabel('Pop World Understanding', fontsize=18)\n",
    "\n",
    "# Adjust layout to prevent label cutoff\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"crit_compare_change.pdf\", dpi=400)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
